diff -uNr /usr/patch/logstash-5.5.0/Gemfile /usr/elk/logstash-5.5.0/Gemfile
--- /usr/patch/logstash-5.5.0/Gemfile	2020-09-11 11:30:21.308000000 +0800
+++ /usr/elk/logstash-5.5.0/Gemfile	2020-08-31 15:47:25.112000000 +0800
@@ -119,3 +119,6 @@
 gem "logstash-output-webhdfs"
 gem "logstash-filter-dissect"
 gem "logstash-input-dead_letter_queue"
+gem "ruby-protocol-buffers", "1.6.1"
+gem "logstash-codec-hw-telemetry-gpb", :path => "/usr/elk/logstash-5.5.0/local-plugins/logstash-codec-telemetry-gpb"
+gem "logstash-input-unix-hw", :path => "/usr/elk/logstash-5.5.0/local-plugins/logstash-input-unix-hw"
diff -uNr /usr/patch/logstash-5.5.0/Gemfile.jruby-1.9.lock /usr/elk/logstash-5.5.0/Gemfile.jruby-1.9.lock
--- /usr/patch/logstash-5.5.0/Gemfile.jruby-1.9.lock	2020-09-11 11:30:21.308000000 +0800
+++ /usr/elk/logstash-5.5.0/Gemfile.jruby-1.9.lock	2020-08-31 15:47:25.112000000 +0800
@@ -30,6 +30,20 @@
     logstash-core-plugin-api (2.1.12-java)
       logstash-core (= 5.5.0)
 
+PATH
+  remote: local-plugins/logstash-codec-telemetry-gpb
+  specs:
+    logstash-codec-hw-telemetry-gpb (0.9.0)
+      logstash-core (>= 1.4.0)
+      ruby-protocol-buffers (>= 1.6.0, < 2.0.0)
+
+PATH
+  remote: local-plugins/logstash-input-unix-hw
+  specs:
+    logstash-input-unix-hw (3.0.4)
+      logstash-codec-line
+      logstash-core-plugin-api (>= 1.60, <= 2.99)
+
 GEM
   remote: https://rubygems.org/
   specs:
@@ -561,6 +575,7 @@
       ruby-maven-libs (~> 3.3.9)
     ruby-maven-libs (3.3.9)
     ruby-progressbar (1.8.1)
+    ruby-protocol-buffers (1.6.1)
     rubyzip (1.1.7)
     rufus-scheduler (3.0.9)
       tzinfo
@@ -636,6 +651,7 @@
   logstash-codec-es_bulk
   logstash-codec-fluent
   logstash-codec-graphite
+  logstash-codec-hw-telemetry-gpb!
   logstash-codec-json
   logstash-codec-json_lines
   logstash-codec-line
@@ -700,6 +716,7 @@
   logstash-input-twitter
   logstash-input-udp
   logstash-input-unix
+  logstash-input-unix-hw!
   logstash-input-xmpp
   logstash-output-cloudwatch
   logstash-output-csv
@@ -732,6 +749,7 @@
   rest-client (= 1.8.0)
   rspec (~> 3.1.0)
   ruby-progressbar (~> 1.8.1)
+  ruby-protocol-buffers (= 1.6.1)
   rubyzip (~> 1.1.7)
   simplecov
   stud (~> 0.0.22)
diff -uNr /usr/patch/logstash-5.5.0/huawei-test/unix_test.conf /usr/elk/logstash-5.5.0/huawei-test/unix_test.conf
--- /usr/patch/logstash-5.5.0/huawei-test/unix_test.conf	2020-09-11 11:30:21.308000000 +0800
+++ /usr/elk/logstash-5.5.0/huawei-test/unix_test.conf	2020-09-04 17:17:43.868000000 +0800
@@ -0,0 +1,27 @@
+input{
+   unix_hw{
+    codec => telemetry_gpb_hw {
+            protofiles => "/usr/elk/logstash-5.5.0/huawei-test/protos/"
+        }
+    path => "/usr/elk/logstash-5.5.0/huawei-test/UNIX.d"
+   } 
+}
+filter {
+ if [sensor_path] == "huawei-devm:devm/ports/port/huawei-pic:optical-module" and [ports.port][0][optical_module][tx_power] and [ports.port][0][optical_module][rx_power] {
+   mutate {
+     add_field  => { "ports.port.optical_module.tx_power_f" => "%{[ports.port][0][optical_module][tx_power]}" }
+     add_field  => { "ports.port.optical_module.rx_power_f" => "%{[ports.port][0][optical_module][rx_power]}" }
+   }
+   mutate {
+     convert => { "ports.port.optical_module.tx_power_f" => "float" }
+     convert => { "ports.port.optical_module.rx_power_f" => "float" }
+   }
+  }
+}
+output{
+   elasticsearch {
+      hosts => "127.0.0.1:9200"
+      index => "logstash-telemetry-%{+YYYY.MM.dd}"
+      document_type => "huawei"
+   }  
+}
diff -uNr /usr/patch/logstash-5.5.0/local-plugins/logstash-codec-telemetry-gpb/logstash-codec-telemetry-gpb/lib/logstash/codecs/telemetry_gpb_hw.rb /usr/elk/logstash-5.5.0/local-plugins/logstash-codec-telemetry-gpb/logstash-codec-telemetry-gpb/lib/logstash/codecs/telemetry_gpb_hw.rb
--- /usr/patch/logstash-5.5.0/local-plugins/logstash-codec-telemetry-gpb/logstash-codec-telemetry-gpb/lib/logstash/codecs/telemetry_gpb_hw.rb	2020-09-11 11:30:21.316000000 +0800
+++ /usr/elk/logstash-5.5.0/local-plugins/logstash-codec-telemetry-gpb/logstash-codec-telemetry-gpb/lib/logstash/codecs/telemetry_gpb_hw.rb	2020-08-31 15:47:25.112000000 +0800
@@ -3,83 +3,15 @@
 require "logstash/codecs/base"
 require "logstash/namespace"
 require 'json'
-
-def telemetry_gpb_camelise s
-  s.split('_').collect {|w| w.capitalize}.join
-end
-
-def telemetry_gpb_extract_cisco_extensions_from_proto protofile
-  #
-  # Function takes care of returning the mapping between schema path
-  # and corresponding class or module::class.
-  #
-  # We rely on the properties of the autogenerated .proto file.  We
-  # expect to find at most one pertinent 'package' instruction in the
-  # .proto file, and we expect one piece of metadata which talks about
-  # paths and schema paths.
-  #
-  modulenames = nil
-  classname = nil
-  path = nil
-  theclass = nil
-
-  f = File.open(protofile, "r")
-  f.each do |line|
-
-    #
-    # Extract module - this is important to protect against name space
-    # pollution (e.g. where multiple sysdb bags point at the same bag)
-    #
-    m = line.match('package \s*(?<modulename>[\w\.]+)\s*;') 
-    if m and m['modulename']
-      modulenames = m['modulename'].split('.').map do |raw|
-        #
-        # We could camelise, but then RootOper becomes Rootoper which
-        # is not what protouf compiler does.
-        #
-        telemetry_gpb_camelise raw
-        #raw
-      end
-    end
-
-    #
-    # Extract bag name and path from metadata.
-    #
-    m = line.match('.*metadata.*\\\"bag\\\": \\\"(?<bag>[\d\w]*)\\\".*\\\"schema_path\\\": \\\"(?<path>[\d\w\.]*)\\\".*') 
-    if m and m['bag'] and m['path']
-      classname = telemetry_gpb_camelise m['bag']
-      path = m['path']
-    end
-
-  end # End of line by line iteration on file.
-
-  f.close
-
-  if path and classname
-    mod = Kernel
-    if modulenames
-      modulenames.each do |modulename|
-        mod = mod.const_get(modulename)
-      end
-    end
-    theclass = mod.const_get(classname)
-  end
-
-  if theclass
-    return [path, [theclass, classname]]
-  end
-
-end
-
+require 'protocol_buffers'
+require 'logger'
+require 'base64'
 #
-# To turn on debugging, modify LS_OPTS in /etc/default/logstash to
-# LS_OPTS="--debug"
-#
-# To view debugs, look at the file pointed at by LS_LOG_FILE
-# which defaults to /var/log/logstash/logstash.log
+# Implementation of a Logstash codec for the Google Protocol Buffer Format(GPB)
+# For Telemetry gpb data
 #
 class LogStash::Codecs::Telemetry_gpb < LogStash::Codecs::Base
-  config_name "telemetry_gpb"
+  config_name "telemetry_gpb_hw"
 
   #
   # 'protofiles' specified path for directory holding:
@@ -102,17 +34,20 @@
   config :protofiles, :validate => :path, :required => true
 
   public
+
   def register
     #
     # Initialise the state of the codec. Codec is always cloned from
     # this state.
     #
-    @logger.info("Registering cisco telemetry_gpb dgram codec")
-
+    # Write error info into file
+    log_file = File.open('./logs/telemetry-gpb.log', 'a')
+    @file_logger = Logger.new(log_file)
+    @file_logger.level = Logger::ERROR
     #
     # Load ruby binding source files for .proto
     #
-    Dir.glob(@protofiles + "/*.pb.rb") do |binding_sourcefile|
+    Dir.glob(@protofiles + "/*.rb") do |binding_sourcefile|
       dir_and_file = File.absolute_path binding_sourcefile
       @logger.info("Loading ruby source file",
                    :proto_binding_source => dir_and_file)
@@ -124,126 +59,177 @@
                      :exception => e, :stacktrace => e.backtrace)
       end
     end
+  end
 
-    #
-    # Build a map of paths to gpb rb binding objects (and name)
-    #
-    # Sample outcome:
-    #
-    # @protofiles_map = {
-    #  "RootOper.FIB.Node.Protocol.VRF.IPPrefixBrief" =>
-    #      [FibShTblFib, "FibShTblFib"],
-    #  "RootOper.InfraStatistics.Interface.Latest.GenericCounters" =>
-    #      [IfstatsbagGeneric, "IfstatsbagGeneric"]
-    #   ...
-    # }
-    #
-    #
-    @protofiles_map =
-      Hash[Dir.glob(@protofiles + "/*.proto").map { |p|
-             telemetry_gpb_extract_cisco_extensions_from_proto p
-           }]
-    @logger.info("Loading ruby path to class map",
-                 :protofiles_map => @protofiles_map.to_s)
+  # @deprecated
+  # deprecated by wangting w30000618 2020/3/4
+  def hash_merge_old(clsname, hashdata)
+    hash_res = Hash.new
+    hashdata.each do |key, value|
+      if value.is_a?(Hash)
+        tmp = "." + key.to_s
+        if clsname.eql?("")
+          tmp = key.to_s
+        end
+        clsname = clsname + tmp
+        new_hash_res = hash_merge(clsname, value)
+        hash_res = hash_res.merge(new_hash_res)
+      else
+        if !clsname.eql?("")
+          key = clsname + "." + key.to_s
+        end
+        value.each do |content|
+          if content.has_key?(:data)
+            data_tmp = Base64.strict_encode64(content[:data])
+            @logger.info(data_tmp);
+            content[:data] = data_tmp
+          end
+        end
+        hash_res[key] = value
+      end
+    end
+    hash_res
+  end
+
+  def hash_merge(clsname, hashdata)
+    hash_res = Hash.new
+    hashdata.each do |key, value|
+      if value.is_a?(Hash)
+        tmp = "." + key.to_s
+        if clsname.eql?("")
+          tmp = key.to_s
+        end
+        clsname = clsname + tmp
+        new_hash_res = hash_merge(clsname, value)
+        hash_res = hash_res.merge(new_hash_res)
+      else
+        if !clsname.eql?("")
+          key = clsname + "." + key.to_s
+        end
+        # add by wangting w30000618 2020/3/4, if value's class not arr, but num; it cannot do .each
+        if (!value.is_a?(Array))
+          hash_res[key] = value
+        else
+          value.each do |content|
+            if content.has_key?(:data)
+              data_tmp = Base64.strict_encode64(content[:data])
+              content[:data] = data_tmp
+            end
+          end
+        end
+        hash_res[key] = value
+      end
+    end
+    hash_res
+  end
 
+
+  # add by wangting 2020.2.28 start
+  def to_hash_with_enum_name(message)
+    return nil if message == nil
+    return message.is_a?(String) ? message.dup : message unless message.is_a?(::ProtocolBuffers::Message)
+    message.fields.select do |tag, field|
+      message.value_for_tag?(tag)
+    end.inject(Hash.new) do |hash, (tag, field)|
+      value = message.value_for_tag(tag)
+      # hash[field.name] = value.is_a?(::ProtocolBuffers::RepeatedField) ? value.map { |elem| to_hash(elem) } : to_hash(value)
+      if !field.is_a?(::ProtocolBuffers::Field::EnumField)
+        hash[field.name] = value.is_a?(::ProtocolBuffers::RepeatedField) ? value.map { |elem| to_hash_with_enum_name(elem) } : to_hash_with_enum_name(value)
+      end
+      if field.is_a?(::ProtocolBuffers::Field::EnumField)
+        if value.is_a?(::ProtocolBuffers::RepeatedField)
+          hash[field.name] = []
+          value.map { |elem|
+            hash[field.name] << field.value_to_name[elem]
+          }
+        else
+          hash[field.name] = field.is_a?(::ProtocolBuffers::Field::EnumField) ? field.value_to_name[value] : value
+        end
+      end
+      hash
+    end
   end
 
+  # add by wangting 2020.2.28 end
+
   public
+
   def decode(data)
 
     connection_thread = Thread.current
 
     @logger.debug? &&
-      @logger.debug("Transport passing data down",
-                    :thread => connection_thread.to_s,
-                    :length => data.length)
+        @logger.debug("Transport passing data down",
+                      :thread => connection_thread.to_s,
+                      :length => data.length)
 
-    msg = TelemetryHeader.new
+    #Huawei Data Decoder
     begin
-      msg_out = msg.parse(data).to_hash
-      tables = msg_out.delete(:tables)
-      tables.each do |table|
-
-        @logger.debug? &&
-          @logger.debug("Message policy paths",
-                        :identifier => msg_out[:identifier],
-                        :policy_name => msg_out[:policy_name],
-                        :end_time => msg_out[:end_time],
-                        :policy_path => table[:policy_path])
+      hwmsg = Hwtelemetry::Telemetry.new
+      # hwmsg_out = hwmsg.parse(data).to_hash   delete by wangting 30000618 2020.2.28
+      hwmsg_out = to_hash_with_enum_name(hwmsg.parse(data)) # add by wangting 30000618 2020.2.28
+      class_path = hwmsg_out[:sensor_path].split("/")
+      moudule_classpre = class_path[0].split(":") #get second class name to create message class
+      moudule_class = moudule_classpre[0].split("-")
+      moudule_prename = moudule_class[0].capitalize
+      module_class_len = moudule_class.length
+      moudule_name = ""
+      i = 1
+      while i < module_class_len
+        mod_tmp = moudule_class[i]
+        mod_tmp[0] = mod_tmp[0].capitalize
+        moudule_name += mod_tmp
+        i += 1
+      end
+      sec_class = moudule_classpre[1].split("-")
+      sec_class_len = sec_class.length
+      sec_name = ""
+      i = 0
+      while i < sec_class_len
+        sec_tmp = sec_class[i]
+        sec_tmp[0] = sec_tmp[0].capitalize
+        sec_name += sec_tmp
+        i += 1
+      end
+      classname = moudule_prename + moudule_name + "::" + sec_name
+      row_class = classname.split('::').inject(Object) { |n, c| n.const_get c }
+      data_gpb = hwmsg_out.delete(:data_gpb)
+      data_rows = data_gpb.delete(:row)
 
-        #
+      data_rows.each do |row|
         # Map row to appropriate sub-message type and decode.
-        #
-        if @protofiles_map.has_key? table[:policy_path]
-          row_decoder_name = @protofiles_map[table[:policy_path]]
-          begin
-
-            row_decoder_class = row_decoder_name[0]
-            rows = table[:row]
-            rows.each do |row|
-
-              @logger.debug? &&
-                @logger.debug("Raw row", :row_raw => row.to_s,
-                              :row_decoder_name => row_decoder_name,
-                              :row_decoder_class => row_decoder_class.to_s)
-
-              #
-              # Perhaps just clear the object as opposed to allocate
-              # it for every iteration.
-              #
-              row_decoder = row_decoder_class.new
-              row_out = row_decoder.parse(row).to_hash
-              @logger.debug? &&
-                @logger.debug("Decoded row",
-                              :row_out => row_out.to_s)
-
-              #
-              # Merge header and row, stringify keys, and yield.
-              #
-              # Stringify operation copes with nested hashes too.
-              # .stringify in rails is what I am looking for, but this
-              # is not rails.
-              #
-              ev = msg_out.clone
-              ev[:end_time] = msg_out[:end_time]
-              ev[:content] = row_out
-              ev[:type] = row_decoder_name[1]
-              ev[:path] = table[:policy_path]
-              yield LogStash::Event.new(JSON.parse(ev.to_json))
-
-            end # End of iteration over rows
-
-          rescue Exception => e
-            @logger.warn("Failed to decode telemetry row",
-                         :policy_path => table[:policy_path],
-                         :decoder => row_decoder_name,
+        row_out = to_hash_with_enum_name(row_class.parse(row[:content]))
+        hwmsg_out[:timestamp] = row[:timestamp]
+        content_out = Hash.new
+        clsname = ""
+        content_out = hash_merge(clsname, row_out)
+        ev = hwmsg_out.clone
+        ev = ev.merge(content_out)
+        #yield LogStash::Event.new(JSON.parse(ev.to_json))
+        yield LogStash::Event.new(ev)
+      end # End of iteration over rows
+
+    rescue Exception => e # Catch Decoder Exception
+      msg = "Failed to decode telemetry data"
+      @logger.error("Failed to decode telemetry data",
+                    :data => data,
+                    :exception => e, :stacktrace => e.backtrace)
+      @file_logger.error(:msg => msg,
+                         :data => data,
                          :exception => e, :stacktrace => e.backtrace)
-          end # End of exception handling of row decode
-
-          @logger.debug? && @logger.debug("Iteration end")
-
-        else # No decoder is available
-
-          @logger.debug? &&
-            @logger.debug("No decoder available",
-                          :policy_path => table[:policy_path])
-
-        end # End of cases where a decoder is available, or not
+    end # End of Exception handling
 
-      end # End of iteration over each table
-
-    rescue Exception => e
-      @logger.warn("Failed to decode telemetry header",
-                   :data => data,
-                   :exception => e, :stacktrace => e.backtrace)
-    end
+  end
 
-  end # def decode
+  # def decode
 
   public
+
   def encode(event)
     # do nothing on encode for now
-    @logger.info("cisco telemetry: no encode facility")
-  end # def encode
+    @logger.info("telemetry: no encode facility")
+  end
+
+# def encode
 
-end # class LogStash::Codecs::TelemetryStream
+end # class LogStash::Codecs::Telemetry_gpb
diff -uNr /usr/patch/logstash-5.5.0/local-plugins/logstash-codec-telemetry-gpb/logstash-codec-telemetry-gpb/logstash-codec-hw-telemetry-gpb.gemspec /usr/elk/logstash-5.5.0/local-plugins/logstash-codec-telemetry-gpb/logstash-codec-telemetry-gpb/logstash-codec-hw-telemetry-gpb.gemspec
--- /usr/patch/logstash-5.5.0/local-plugins/logstash-codec-telemetry-gpb/logstash-codec-telemetry-gpb/logstash-codec-hw-telemetry-gpb.gemspec	2020-09-11 11:30:21.316000000 +0800
+++ /usr/elk/logstash-5.5.0/local-plugins/logstash-codec-telemetry-gpb/logstash-codec-telemetry-gpb/logstash-codec-hw-telemetry-gpb.gemspec	2020-08-31 15:47:25.112000000 +0800
@@ -1,5 +1,5 @@
 Gem::Specification.new do |s|
-  s.name = 'logstash-codec-telemetry-gpb'
+  s.name = 'logstash-codec-hw-telemetry-gpb'
   s.version         = '0.9.0'
   s.licenses = ['Apache License (2.0)']
   s.summary = "This codec handles cisco telemetry (gpb dgrams)."
@@ -19,7 +19,7 @@
   s.metadata = { "logstash_plugin" => "true", "logstash_group" => "codec" }
 
   # Gem dependencies
-  s.add_runtime_dependency "logstash-core", '>= 1.4.0', '< 3.0.0'
+  s.add_runtime_dependency "logstash-core", '>= 1.4.0'
   s.add_runtime_dependency "ruby-protocol-buffers", '>= 1.6.0', '< 2.0.0'
 
   s.add_development_dependency 'logstash-devutils'
diff -uNr /usr/patch/logstash-5.5.0/local-plugins/logstash-codec-telemetry-gpb/logstash-codec-telemetry-gpb/resources/xr6.0.0/cisco.proto /usr/elk/logstash-5.5.0/local-plugins/logstash-codec-telemetry-gpb/logstash-codec-telemetry-gpb/resources/xr6.0.0/cisco.proto
--- /usr/patch/logstash-5.5.0/local-plugins/logstash-codec-telemetry-gpb/logstash-codec-telemetry-gpb/resources/xr6.0.0/cisco.proto	2020-09-11 11:30:21.316000000 +0800
+++ /usr/elk/logstash-5.5.0/local-plugins/logstash-codec-telemetry-gpb/logstash-codec-telemetry-gpb/resources/xr6.0.0/cisco.proto	1970-01-01 08:00:00.000000000 +0800
@@ -1,50 +0,0 @@
-/* ----------------------------------------------------------------------------
- * cisco.proto -- Protocol Buffer extension definitions
- *
- * August 2015, Robert Wills
- *
- * Copyright (c) 2015 by Cisco Systems, Inc.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- * ----------------------------------------------------------------------------
- */
-
-syntax = "proto2";
-
-import "google/protobuf/descriptor.proto";
-
-message CiscoMessageOptions {
-    optional string schema_path = 1;
-}
-
-message CiscoFieldOptions {
-    optional string name = 1;
-    optional string path_element = 2;
-}
-
-message CiscoFileOptions {
-    optional string metadata = 1;
-}
-
-extend google.protobuf.MessageOptions {
-    optional CiscoMessageOptions cisco_msg = 29051;
-}
-
-extend google.protobuf.FieldOptions {
-    optional CiscoFieldOptions cisco_field = 29052;
-}
-
-extend google.protobuf.FileOptions {
-    optional CiscoFileOptions cisco_file = 29053;
-}
-
diff -uNr /usr/patch/logstash-5.5.0/local-plugins/logstash-codec-telemetry-gpb/logstash-codec-telemetry-gpb/resources/xr6.0.0/descriptor.proto /usr/elk/logstash-5.5.0/local-plugins/logstash-codec-telemetry-gpb/logstash-codec-telemetry-gpb/resources/xr6.0.0/descriptor.proto
--- /usr/patch/logstash-5.5.0/local-plugins/logstash-codec-telemetry-gpb/logstash-codec-telemetry-gpb/resources/xr6.0.0/descriptor.proto	2020-09-11 11:30:21.316000000 +0800
+++ /usr/elk/logstash-5.5.0/local-plugins/logstash-codec-telemetry-gpb/logstash-codec-telemetry-gpb/resources/xr6.0.0/descriptor.proto	1970-01-01 08:00:00.000000000 +0800
@@ -1,433 +0,0 @@
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-// Author: kenton@google.com (Kenton Varda)
-//  Based on original Protocol Buffers design by
-//  Sanjay Ghemawat, Jeff Dean, and others.
-//
-// The messages in this file describe the definitions found in .proto files.
-// A valid .proto file can be translated directly to a FileDescriptorProto
-// without any other information (e.g. without reading its imports).
-
-
-
-package google.protobuf;
-option java_package = "com.google.protobuf";
-option java_outer_classname = "DescriptorProtos";
-
-// descriptor.proto must be optimized for speed because reflection-based
-// algorithms don't work during bootstrapping.
-option optimize_for = SPEED;
-
-// The protocol compiler can output a FileDescriptorSet containing the .proto
-// files it parses.
-message FileDescriptorSet {
-  repeated FileDescriptorProto file = 1;
-}
-
-// Describes a complete .proto file.
-message FileDescriptorProto {
-  optional string name = 1;       // file name, relative to root of source tree
-  optional string package = 2;    // e.g. "foo", "foo.bar", etc.
-
-  // Names of files imported by this file.
-  repeated string dependency = 3;
-
-  // All top-level definitions in this file.
-  repeated DescriptorProto message_type = 4;
-  repeated EnumDescriptorProto enum_type = 5;
-  repeated ServiceDescriptorProto service = 6;
-  repeated FieldDescriptorProto extension = 7;
-
-  optional FileOptions options = 8;
-}
-
-// Describes a message type.
-message DescriptorProto {
-  optional string name = 1;
-
-  repeated FieldDescriptorProto field = 2;
-  repeated FieldDescriptorProto extension = 6;
-
-  repeated DescriptorProto nested_type = 3;
-  repeated EnumDescriptorProto enum_type = 4;
-
-  message ExtensionRange {
-    optional int32 start = 1;
-    optional int32 end = 2;
-  }
-  repeated ExtensionRange extension_range = 5;
-
-  optional MessageOptions options = 7;
-}
-
-// Describes a field within a message.
-message FieldDescriptorProto {
-  enum Type {
-    // 0 is reserved for errors.
-    // Order is weird for historical reasons.
-    TYPE_DOUBLE         = 1;
-    TYPE_FLOAT          = 2;
-    TYPE_INT64          = 3;   // Not ZigZag encoded.  Negative numbers
-                               // take 10 bytes.  Use TYPE_SINT64 if negative
-                               // values are likely.
-    TYPE_UINT64         = 4;
-    TYPE_INT32          = 5;   // Not ZigZag encoded.  Negative numbers
-                               // take 10 bytes.  Use TYPE_SINT32 if negative
-                               // values are likely.
-    TYPE_FIXED64        = 6;
-    TYPE_FIXED32        = 7;
-    TYPE_BOOL           = 8;
-    TYPE_STRING         = 9;
-    TYPE_GROUP          = 10;  // Tag-delimited aggregate.
-    TYPE_MESSAGE        = 11;  // Length-delimited aggregate.
-
-    // New in version 2.
-    TYPE_BYTES          = 12;
-    TYPE_UINT32         = 13;
-    TYPE_ENUM           = 14;
-    TYPE_SFIXED32       = 15;
-    TYPE_SFIXED64       = 16;
-    TYPE_SINT32         = 17;  // Uses ZigZag encoding.
-    TYPE_SINT64         = 18;  // Uses ZigZag encoding.
-  };
-
-  enum Label {
-    // 0 is reserved for errors
-    LABEL_OPTIONAL      = 1;
-    LABEL_REQUIRED      = 2;
-    LABEL_REPEATED      = 3;
-    // TODO(sanjay): Should we add LABEL_MAP?
-  };
-
-  optional string name = 1;
-  optional int32 number = 3;
-  optional Label label = 4;
-
-  // If type_name is set, this need not be set.  If both this and type_name
-  // are set, this must be either TYPE_ENUM or TYPE_MESSAGE.
-  optional Type type = 5;
-
-  // For message and enum types, this is the name of the type.  If the name
-  // starts with a '.', it is fully-qualified.  Otherwise, C++-like scoping
-  // rules are used to find the type (i.e. first the nested types within this
-  // message are searched, then within the parent, on up to the root
-  // namespace).
-  optional string type_name = 6;
-
-  // For extensions, this is the name of the type being extended.  It is
-  // resolved in the same manner as type_name.
-  optional string extendee = 2;
-
-  // For numeric types, contains the original text representation of the value.
-  // For booleans, "true" or "false".
-  // For strings, contains the default text contents (not escaped in any way).
-  // For bytes, contains the C escaped value.  All bytes >= 128 are escaped.
-  // TODO(kenton):  Base-64 encode?
-  optional string default_value = 7;
-
-  optional FieldOptions options = 8;
-}
-
-// Describes an enum type.
-message EnumDescriptorProto {
-  optional string name = 1;
-
-  repeated EnumValueDescriptorProto value = 2;
-
-  optional EnumOptions options = 3;
-}
-
-// Describes a value within an enum.
-message EnumValueDescriptorProto {
-  optional string name = 1;
-  optional int32 number = 2;
-
-  optional EnumValueOptions options = 3;
-}
-
-// Describes a service.
-message ServiceDescriptorProto {
-  optional string name = 1;
-  repeated MethodDescriptorProto method = 2;
-
-  optional ServiceOptions options = 3;
-}
-
-// Describes a method of a service.
-message MethodDescriptorProto {
-  optional string name = 1;
-
-  // Input and output type names.  These are resolved in the same way as
-  // FieldDescriptorProto.type_name, but must refer to a message type.
-  optional string input_type = 2;
-  optional string output_type = 3;
-
-  optional MethodOptions options = 4;
-}
-
-// ===================================================================
-// Options
-
-// Each of the definitions above may have "options" attached.  These are
-// just annotations which may cause code to be generated slightly differently
-// or may contain hints for code that manipulates protocol messages.
-//
-// Clients may define custom options as extensions of the *Options messages.
-// These extensions may not yet be known at parsing time, so the parser cannot
-// store the values in them.  Instead it stores them in a field in the *Options
-// message called uninterpreted_option. This field must have the same name
-// across all *Options messages. We then use this field to populate the
-// extensions when we build a descriptor, at which point all protos have been
-// parsed and so all extensions are known.
-//
-// Extension numbers for custom options may be chosen as follows:
-// * For options which will only be used within a single application or
-//   organization, or for experimental options, use field numbers 50000
-//   through 99999.  It is up to you to ensure that you do not use the
-//   same number for multiple options.
-// * For options which will be published and used publicly by multiple
-//   independent entities, e-mail kenton@google.com to reserve extension
-//   numbers.  Simply tell me how many you need and I'll send you back a
-//   set of numbers to use -- there's no need to explain how you intend to
-//   use them.  If this turns out to be popular, a web service will be set up
-//   to automatically assign option numbers.
-
-
-message FileOptions {
-
-  // Sets the Java package where classes generated from this .proto will be
-  // placed.  By default, the proto package is used, but this is often
-  // inappropriate because proto packages do not normally start with backwards
-  // domain names.
-  optional string java_package = 1;
-
-
-  // If set, all the classes from the .proto file are wrapped in a single
-  // outer class with the given name.  This applies to both Proto1
-  // (equivalent to the old "--one_java_file" option) and Proto2 (where
-  // a .proto always translates to a single class, but you may want to
-  // explicitly choose the class name).
-  optional string java_outer_classname = 8;
-
-  // If set true, then the Java code generator will generate a separate .java
-  // file for each top-level message, enum, and service defined in the .proto
-  // file.  Thus, these types will *not* be nested inside the outer class
-  // named by java_outer_classname.  However, the outer class will still be
-  // generated to contain the file's getDescriptor() method as well as any
-  // top-level extensions defined in the file.
-  optional bool java_multiple_files = 10 [default=false];
-
-  // Generated classes can be optimized for speed or code size.
-  enum OptimizeMode {
-    SPEED = 1;        // Generate complete code for parsing, serialization,
-                      // etc.
-    CODE_SIZE = 2;    // Use ReflectionOps to implement these methods.
-    LITE_RUNTIME = 3; // Generate code using MessageLite and the lite runtime.
-  }
-  optional OptimizeMode optimize_for = 9 [default=SPEED];
-
-
-
-
-  // Should generic services be generated in each language?  "Generic" services
-  // are not specific to any particular RPC system.  They are generated by the
-  // main code generators in each language (without additional plugins).
-  // Generic services were the only kind of service generation supported by
-  // early versions of proto2.
-  //
-  // Generic services are now considered deprecated in favor of using plugins
-  // that generate code specific to your particular RPC system.  If you are
-  // using such a plugin, set these to false.  In the future, we may change
-  // the default to false, so if you explicitly want generic services, you
-  // should explicitly set these to true.
-  optional bool cc_generic_services = 16 [default=true];
-  optional bool java_generic_services = 17 [default=true];
-  optional bool py_generic_services = 18 [default=true];
-
-  // The parser stores options it doesn't recognize here. See above.
-  repeated UninterpretedOption uninterpreted_option = 999;
-
-  // Clients can define custom options in extensions of this message. See above.
-  extensions 1000 to max;
-}
-
-message MessageOptions {
-  // Set true to use the old proto1 MessageSet wire format for extensions.
-  // This is provided for backwards-compatibility with the MessageSet wire
-  // format.  You should not use this for any other reason:  It's less
-  // efficient, has fewer features, and is more complicated.
-  //
-  // The message must be defined exactly as follows:
-  //   message Foo {
-  //     option message_set_wire_format = true;
-  //     extensions 4 to max;
-  //   }
-  // Note that the message cannot have any defined fields; MessageSets only
-  // have extensions.
-  //
-  // All extensions of your type must be singular messages; e.g. they cannot
-  // be int32s, enums, or repeated messages.
-  //
-  // Because this is an option, the above two restrictions are not enforced by
-  // the protocol compiler.
-  optional bool message_set_wire_format = 1 [default=false];
-
-  // Disables the generation of the standard "descriptor()" accessor, which can
-  // conflict with a field of the same name.  This is meant to make migration
-  // from proto1 easier; new code should avoid fields named "descriptor".
-  optional bool no_standard_descriptor_accessor = 2 [default=false];
-
-  // The parser stores options it doesn't recognize here. See above.
-  repeated UninterpretedOption uninterpreted_option = 999;
-
-  // Clients can define custom options in extensions of this message. See above.
-  extensions 1000 to max;
-}
-
-message FieldOptions {
-  // The ctype option instructs the C++ code generator to use a different
-  // representation of the field than it normally would.  See the specific
-  // options below.  This option is not yet implemented in the open source
-  // release -- sorry, we'll try to include it in a future version!
-  optional CType ctype = 1 [default = STRING];
-  enum CType {
-    // Default mode.
-    STRING = 0;
-
-    CORD = 1;
-
-    STRING_PIECE = 2;
-  }
-  // The packed option can be enabled for repeated primitive fields to enable
-  // a more efficient representation on the wire. Rather than repeatedly
-  // writing the tag and type for each element, the entire array is encoded as
-  // a single length-delimited blob.
-  optional bool packed = 2;
-
-
-  // Is this field deprecated?
-  // Depending on the target platform, this can emit Deprecated annotations
-  // for accessors, or it will be completely ignored; in the very least, this
-  // is a formalization for deprecating fields.
-  optional bool deprecated = 3 [default=false];
-
-  // EXPERIMENTAL.  DO NOT USE.
-  // For "map" fields, the name of the field in the enclosed type that
-  // is the key for this map.  For example, suppose we have:
-  //   message Item {
-  //     required string name = 1;
-  //     required string value = 2;
-  //   }
-  //   message Config {
-  //     repeated Item items = 1 [experimental_map_key="name"];
-  //   }
-  // In this situation, the map key for Item will be set to "name".
-  // TODO: Fully-implement this, then remove the "experimental_" prefix.
-  optional string experimental_map_key = 9;
-
-  // The parser stores options it doesn't recognize here. See above.
-  repeated UninterpretedOption uninterpreted_option = 999;
-
-  // Clients can define custom options in extensions of this message. See above.
-  extensions 1000 to max;
-}
-
-message EnumOptions {
-
-  // The parser stores options it doesn't recognize here. See above.
-  repeated UninterpretedOption uninterpreted_option = 999;
-
-  // Clients can define custom options in extensions of this message. See above.
-  extensions 1000 to max;
-}
-
-message EnumValueOptions {
-  // The parser stores options it doesn't recognize here. See above.
-  repeated UninterpretedOption uninterpreted_option = 999;
-
-  // Clients can define custom options in extensions of this message. See above.
-  extensions 1000 to max;
-}
-
-message ServiceOptions {
-
-  // Note:  Field numbers 1 through 32 are reserved for Google's internal RPC
-  //   framework.  We apologize for hoarding these numbers to ourselves, but
-  //   we were already using them long before we decided to release Protocol
-  //   Buffers.
-
-  // The parser stores options it doesn't recognize here. See above.
-  repeated UninterpretedOption uninterpreted_option = 999;
-
-  // Clients can define custom options in extensions of this message. See above.
-  extensions 1000 to max;
-}
-
-message MethodOptions {
-
-  // Note:  Field numbers 1 through 32 are reserved for Google's internal RPC
-  //   framework.  We apologize for hoarding these numbers to ourselves, but
-  //   we were already using them long before we decided to release Protocol
-  //   Buffers.
-
-  // The parser stores options it doesn't recognize here. See above.
-  repeated UninterpretedOption uninterpreted_option = 999;
-
-  // Clients can define custom options in extensions of this message. See above.
-  extensions 1000 to max;
-}
-
-// A message representing a option the parser does not recognize. This only
-// appears in options protos created by the compiler::Parser class.
-// DescriptorPool resolves these when building Descriptor objects. Therefore,
-// options protos in descriptor objects (e.g. returned by Descriptor::options(),
-// or produced by Descriptor::CopyTo()) will never have UninterpretedOptions
-// in them.
-message UninterpretedOption {
-  // The name of the uninterpreted option.  Each string represents a segment in
-  // a dot-separated name.  is_extension is true iff a segment represents an
-  // extension (denoted with parentheses in options specs in .proto files).
-  // E.g.,{ ["foo", false], ["bar.baz", true], ["qux", false] } represents
-  // "foo.(bar.baz).qux".
-  message NamePart {
-    required string name_part = 1;
-    required bool is_extension = 2;
-  }
-  repeated NamePart name = 2;
-
-  // The value of the uninterpreted option, in whatever type the tokenizer
-  // identified it as during parsing. Exactly one of these should be set.
-  optional string identifier_value = 3;
-  optional uint64 positive_int_value = 4;
-  optional int64 negative_int_value = 5;
